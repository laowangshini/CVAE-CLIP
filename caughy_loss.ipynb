{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 1272/1272 [01:02<00:00, 20.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 1272/1272 [01:03<00:00, 20.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 1272/1272 [01:02<00:00, 20.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 1272/1272 [01:02<00:00, 20.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 1272/1272 [01:03<00:00, 20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 1272/1272 [01:03<00:00, 20.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, 平均训练损失: nan\n",
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 1272/1272 [01:03<00:00, 20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 1272/1272 [01:03<00:00, 20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 1272/1272 [01:03<00:00, 20.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 1272/1272 [01:02<00:00, 20.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 1272/1272 [01:02<00:00, 20.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 1272/1272 [01:03<00:00, 20.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 1272/1272 [01:02<00:00, 20.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 1272/1272 [01:02<00:00, 20.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 1272/1272 [01:02<00:00, 20.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 1272/1272 [01:03<00:00, 20.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 1272/1272 [01:02<00:00, 20.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, 平均训练损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 1272/1272 [01:02<00:00, 20.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, 平均训练损失: nan\n",
      "验证集平均损失: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20:  73%|███████▎  | 923/1272 [00:46<00:17, 19.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 284\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generated\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# 保存模型\u001b[39;00m\n\u001b[1;32m    287\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(trained_model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip_cvae_celeba_cs_div.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 239\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m    237\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(recon_batch, data, mu, logvar)\n\u001b[1;32m    238\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 239\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    242\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import clip\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# 设备选择\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 加载CLIP模型\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# 文本提示词\n",
    "TEXT_PROMPTS = [\n",
    "    \"A portrait of a young woman\",\n",
    "    \"A realistic face with a smile\",\n",
    "    \"A person with distinct facial features\"\n",
    "]\n",
    "\n",
    "# 生成CLIP文本嵌入（提前计算以避免重复计算）\n",
    "def generate_text_embeddings(text_prompts):\n",
    "    text_tokens = clip.tokenize(text_prompts).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_embeddings = clip_model.encode_text(text_tokens)\n",
    "    return text_embeddings.cpu()  # 移动到CPU\n",
    "\n",
    "# 预先计算文本嵌入\n",
    "CLIP_TEXT_EMBEDDINGS = generate_text_embeddings(TEXT_PROMPTS)\n",
    "\n",
    "# CelebA数据集类\n",
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, img_dir, attr_path, bbox_path, partition_path, \n",
    "                 transform=None, partition=0):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        :param img_dir: 图像文件夹路径\n",
    "        :param attr_path: 属性文件路径\n",
    "        :param bbox_path: 边界框文件路径\n",
    "        :param partition_path: 分区文件路径\n",
    "        :param transform: 图像预处理\n",
    "        :param partition: 使用的数据分区 (0: train, 1: val, 2: test)\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 读取属性文件\n",
    "        attr_df = pd.read_csv(attr_path, sep=',', header=0)\n",
    "        partition_df = pd.read_csv(partition_path, sep=',', header=0)\n",
    "        \n",
    "        # 合并属性文件和分区文件\n",
    "        attr_df = attr_df.merge(partition_df, on='image_id')\n",
    "        \n",
    "        # 根据指定的分区进行筛选\n",
    "        self.attr_df = attr_df[attr_df['partition'] == partition]\n",
    "        \n",
    "        # 读取边界框文件\n",
    "        bbox_df = pd.read_csv(bbox_path, sep=',', header=0)\n",
    "        \n",
    "        # 合并边界框信息\n",
    "        self.attr_df = self.attr_df.merge(bbox_df, on='image_id')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.attr_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 获取图像文件名\n",
    "        img_name = self.attr_df.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        \n",
    "        # 打开图像并转换为RGB\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # 获取属性标签 \n",
    "        attrs = self.attr_df.iloc[idx, 1:41].values\n",
    "        attrs = (attrs + 1) // 2  # 将-1转为0，1保持1\n",
    "        attrs = attrs.astype(np.float32)\n",
    "        \n",
    "        # 应用图像预处理\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # 随机选择一个CLIP文本嵌入\n",
    "        random_idx = random.randint(0, len(CLIP_TEXT_EMBEDDINGS) - 1)\n",
    "        clip_embedding = CLIP_TEXT_EMBEDDINGS[random_idx]\n",
    "        \n",
    "        return image, attrs, clip_embedding\n",
    "\n",
    "class ClipCVAE(nn.Module):\n",
    "    def __init__(self, img_channels=3, img_size=64, latent_dim=128, \n",
    "                 cond_dim=40, clip_dim=512):\n",
    "        super(ClipCVAE, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        self.clip_dim = clip_dim\n",
    "\n",
    "        # 编码器部分\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(img_channels + cond_dim + clip_dim, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(512*4*4, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(512*4*4, latent_dim)\n",
    "\n",
    "        # 解码器部分\n",
    "        self.decoder_input = nn.Linear(latent_dim + cond_dim + clip_dim, 512*4*4)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, img_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, x, c, clip_embedding):\n",
    "        # 将条件标签、图像和CLIP嵌入拼接\n",
    "        c = c.view(c.size(0), self.cond_dim, 1, 1).repeat(1, 1, self.img_size, self.img_size)\n",
    "        clip_embedding = clip_embedding.view(clip_embedding.size(0), self.clip_dim, 1, 1).repeat(1, 1, self.img_size, self.img_size)\n",
    "        x = torch.cat([x, c, clip_embedding], dim=1)\n",
    "        x = self.encoder(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, c, clip_embedding):\n",
    "        # 将潜在变量、条件标签和CLIP嵌入拼接\n",
    "        z = torch.cat([z, c, clip_embedding], dim=1)\n",
    "        x = self.decoder_input(z)\n",
    "        x = x.view(-1, 512, 4, 4)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, c, clip_embedding):\n",
    "        mu, logvar = self.encode(x, c, clip_embedding)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z, c, clip_embedding)\n",
    "        return recon_x, mu, logvar\n",
    "\n",
    "# 图像预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # 修正归一化\n",
    "])\n",
    "\n",
    "# 数据集路径设置（请根据实际路径修改）\n",
    "img_dir = '/root/autodl-tmp/celeba_datasets/img_align_celeba/img_align_celeba'\n",
    "attr_path = '/root/autodl-tmp/celeba_datasets/list_attr_celeba.txt'\n",
    "bbox_path = '/root/autodl-tmp/celeba_datasets/list_bbox_celeba.txt'\n",
    "partition_path = '/root/autodl-tmp/celeba_datasets/list_eval_partition.txt'\n",
    "\n",
    "# 创建训练集和验证集\n",
    "train_dataset = CelebADataset(img_dir, attr_path, bbox_path, partition_path, \n",
    "                              transform=transform, partition=0)\n",
    "val_dataset = CelebADataset(img_dir, attr_path, bbox_path, partition_path, \n",
    "                            transform=transform, partition=1)\n",
    "\n",
    "# 数据加载器\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "latent_dim = 128\n",
    "cond_dim = 40\n",
    "clip_dim = 512\n",
    "model = ClipCVAE(img_channels=3, img_size=64, latent_dim=latent_dim, \n",
    "                 cond_dim=cond_dim, clip_dim=clip_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "# 定义Cauchy-Schwarz散度\n",
    "epsilon = 1e-8  # 为了数值稳定性\n",
    "\n",
    "def cs_divergence(mu, logvar):\n",
    "    \"\"\"\n",
    "    计算Cauchy-Schwarz散度\n",
    "    :param mu: 潜在空间均值，形状为 (batch_size, latent_dim)\n",
    "    :param logvar: 潜在空间对数方差，形状为 (batch_size, latent_dim)\n",
    "    :return: Cauchy-Schwarz散度，标量\n",
    "    \"\"\"\n",
    "    sigma = torch.exp(0.5 * logvar)  # 计算标准差\n",
    "    term1 = torch.log(sigma + epsilon) - 0.5 * torch.log(sigma**2 + 1 + epsilon)\n",
    "    term2 = 0.125 * (mu**2) / (sigma**2 + 1 + epsilon)\n",
    "    cs_div = torch.sum(term1 + term2, dim=1)  # 对每个样本的所有潜在维度求和\n",
    "    return torch.mean(cs_div)  # 返回批次的平均散度\n",
    "\n",
    "# 定义新的损失函数\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    recon_loss = criterion(recon_x, x)\n",
    "    cs_div = cs_divergence(mu, logvar)\n",
    "    return recon_loss + cs_div\n",
    "\n",
    "# 训练模型\n",
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=50):\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, (data, attrs, clip_emb) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs}\")):\n",
    "            data = data.to(device, non_blocking=True)\n",
    "            attrs = attrs.to(device, non_blocking=True)\n",
    "            clip_emb = clip_emb.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(data, attrs, clip_emb)\n",
    "            loss = loss_function(recon_batch, data, mu, logvar)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_loss = train_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch}, 平均训练损失: {avg_loss:.4f}\")\n",
    "        \n",
    "        # 验证集评估\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data, attrs, clip_emb in val_loader:\n",
    "                data = data.to(device, non_blocking=True)\n",
    "                attrs = attrs.to(device, non_blocking=True)\n",
    "                clip_emb = clip_emb.to(device, non_blocking=True)\n",
    "                recon_batch, mu, logvar = model(data, attrs, clip_emb)\n",
    "                loss = loss_function(recon_batch, data, mu, logvar)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        print(f\"验证集平均损失: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 图像生成函数\n",
    "def generate_images(model, attrs, text_prompts, device, num_images=16):\n",
    "    \"\"\"\n",
    "    根据条件标签和文本提示生成图像\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_images, model.latent_dim).to(device)\n",
    "        attrs = attrs[:num_images].to(device)\n",
    "        \n",
    "        # 对于每个图像随机选择一个文本嵌入\n",
    "        text_embeddings = torch.stack([\n",
    "            CLIP_TEXT_EMBEDDINGS[random.randint(0, len(CLIP_TEXT_EMBEDDINGS) - 1)] \n",
    "            for _ in range(num_images)\n",
    "        ]).to(device)\n",
    "        \n",
    "        generated = model.decode(z, attrs, text_embeddings)\n",
    "        generated = generated.cpu()\n",
    "        return generated\n",
    "\n",
    "# 训练模型\n",
    "trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs=20)\n",
    "\n",
    "# 保存模型\n",
    "torch.save(trained_model.state_dict(), 'clip_cvae_celeba_cs_div.pth')\n",
    "\n",
    "# 生成图像示例\n",
    "data_iter = iter(val_loader)\n",
    "images, attrs, _ = next(data_iter)\n",
    "sample_attrs = attrs[:16]\n",
    "\n",
    "generated_images = generate_images(trained_model, sample_attrs, TEXT_PROMPTS, device, num_images=16)\n",
    "\n",
    "# 可视化生成的图像\n",
    "def show_images(images, title=\"Generated Images\"):\n",
    "    images = images * 0.5 + 0.5  # 反归一化\n",
    "    grid = torchvision.utils.make_grid(images, nrow=4)\n",
    "    np_grid = grid.numpy()\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(np.transpose(np_grid, (1, 2, 0)))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_images(generated_images, title=\"CLIP引导的条件生成人脸图像 (Cauchy-Schwarz Divergence)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用Cauchy-Schwarz Divergence代替原理的KLdivergence,重新进行训练。请前检查Cauchy-Schwarz Divergence是什么样的结构，再在代码中替换。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorc_test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
