{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模块1：环境配置与数据集定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "# 模块1：数据集和数据加载相关代码\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# 检查GPU是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, img_dir, attr_path, bbox_path, partition_path, transform=None, partition=0):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 读取属性文件\n",
    "        attr_df = pd.read_csv(attr_path, sep=',', header=0)\n",
    "        partition_df = pd.read_csv(partition_path, sep=',', header=0)\n",
    "        attr_df = attr_df.merge(partition_df, on='image_id')\n",
    "        self.attr_df = attr_df[attr_df['partition'] == partition]\n",
    "\n",
    "        bbox_df = pd.read_csv(bbox_path, sep=',', header=0)\n",
    "        self.attr_df = self.attr_df.merge(bbox_df, on='image_id')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.attr_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.attr_df.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        attrs = self.attr_df.iloc[idx, 1:41].values\n",
    "        attrs = (attrs + 1) // 2\n",
    "        attrs = attrs.astype(np.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, attrs\n",
    "\n",
    "# 定义图像预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)  # 对RGB三通道使用相同的归一化\n",
    "])\n",
    "\n",
    "# 数据集路径设置（请根据实际路径修改）\n",
    "img_dir = '/root/autodl-tmp/celeba_datasets/img_align_celeba/img_align_celeba'\n",
    "attr_path = '/root/autodl-tmp/celeba_datasets/list_attr_celeba.txt'\n",
    "bbox_path = '/root/autodl-tmp/celeba_datasets/list_bbox_celeba.txt'\n",
    "partition_path = '/root/autodl-tmp/celeba_datasets/list_eval_partition.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模块2：加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模块2：创建数据加载器\n",
    "\n",
    "def get_dataloaders(batch_size=128, num_workers=4):\n",
    "    train_dataset = CelebADataset(img_dir, attr_path, bbox_path, partition_path, transform=transform, partition=0)\n",
    "    val_dataset = CelebADataset(img_dir, attr_path, bbox_path, partition_path, transform=transform, partition=1)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模块3：定义CVAE模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模块3：定义CVAE模型\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, img_channels=3, img_size=64, latent_dim=128, cond_dim=40):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.cond_dim = cond_dim\n",
    "\n",
    "        # 编码器\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(img_channels + cond_dim, 64, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(512*4*4, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(512*4*4, latent_dim)\n",
    "\n",
    "        # 解码器\n",
    "        self.decoder_input = nn.Linear(latent_dim + cond_dim, 512*4*4)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, x, c):\n",
    "        c = c.view(c.size(0), self.cond_dim, 1, 1).repeat(1, 1, self.img_size, self.img_size)\n",
    "        x = torch.cat([x, c], dim=1)\n",
    "        x = self.encoder(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, c):\n",
    "        z = torch.cat([z, c], dim=1)\n",
    "        x = self.decoder_input(z)\n",
    "        x = x.view(-1, 512, 4, 4)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        mu, logvar = self.encode(x, c)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z, c)\n",
    "        return recon_x, mu, logvar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模块4：定义损失函数与训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模块4：训练与验证函数以及损失函数定义\n",
    "\n",
    "criterion = nn.MSELoss(reduction='sum')  # 重建损失使用MSE\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    recon_loss = criterion(recon_x, x)\n",
    "    KL = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + KL\n",
    "\n",
    "def train_one_epoch(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data, attrs in train_loader:\n",
    "        data = data.to(device)\n",
    "        attrs = attrs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data, attrs)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    return avg_loss\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, attrs in val_loader:\n",
    "            data = data.to(device)\n",
    "            attrs = attrs.to(device)\n",
    "            recon_batch, mu, logvar = model(data, attrs)\n",
    "            loss = loss_function(recon_batch, data, mu, logvar)\n",
    "            val_loss += loss.item()\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    return avg_val_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模块5：单次训练流程与结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模块5：单次训练流程\n",
    "# 您可以调用此模块进行一次训练过程（固定epoch次数），并返回训练与验证损失列表。\n",
    "\n",
    "def train_model(epochs=20, latent_dim=128, cond_dim=40, learning_rate=1e-3):\n",
    "    model = CVAE(latent_dim=latent_dim, cond_dim=cond_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_loader, val_loader = get_dataloaders()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, device)\n",
    "        val_loss = validate(model, val_loader, device)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "# 可视化损失曲线的函数\n",
    "def plot_losses(train_losses, val_losses, title=\"Training Curve\"):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模块6：生成图像和属性修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模块6：图像生成与展示函数\n",
    "\n",
    "def generate_images(model, attrs, device, latent_dim=128, num_images=16):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_images, latent_dim).to(device)\n",
    "        attrs = attrs.to(device)\n",
    "        generated = model.decode(z, attrs)\n",
    "        generated = generated.cpu()\n",
    "        return generated\n",
    "    \n",
    "def show_images(images, title=\"Generated Images\", save_path=None):\n",
    "    images = images * 0.5 + 0.5  # 反归一化\n",
    "    grid = torchvision.utils.make_grid(images, nrow=4)\n",
    "    np_grid = grid.numpy()\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(np.transpose(np_grid, (1, 2, 0)))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# def show_images(images, title=\"Generated Images\"):\n",
    "#     images = images * 0.5 + 0.5  # 反归一化\n",
    "#     grid = torchvision.utils.make_grid(images, nrow=4)\n",
    "#     np_grid = grid.numpy()\n",
    "#     plt.figure(figsize=(8,8))\n",
    "#     plt.imshow(np.transpose(np_grid, (1, 2, 0)))\n",
    "#     plt.title(title)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模块7：单次实验示例与结果展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')  # 使用非交互式后端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 389729380663.9202, Val Loss: 1441.0903\n",
      "Epoch 2, Train Loss: 1228.4961, Val Loss: 1218.4309\n",
      "Epoch 3, Train Loss: 1084.6629, Val Loss: 1082.5778\n",
      "Epoch 4, Train Loss: 991.3360, Val Loss: 930.8724\n",
      "Epoch 5, Train Loss: 936.0570, Val Loss: 964.3071\n",
      "Epoch 6, Train Loss: 902.4863, Val Loss: 872.2933\n",
      "Epoch 7, Train Loss: 866.2246, Val Loss: 899.5244\n",
      "Epoch 8, Train Loss: 844.9742, Val Loss: 849.2684\n",
      "Epoch 9, Train Loss: 825.8536, Val Loss: 847.0976\n",
      "Epoch 10, Train Loss: 808.1083, Val Loss: 878.3733\n",
      "Epoch 11, Train Loss: 801.5370, Val Loss: 819.8101\n",
      "Epoch 12, Train Loss: 784.7714, Val Loss: 803.3191\n",
      "Epoch 13, Train Loss: 780.1961, Val Loss: 779.1673\n",
      "Epoch 14, Train Loss: 769.2927, Val Loss: 804.9587\n",
      "Epoch 15, Train Loss: 765.6936, Val Loss: 779.0623\n",
      "Epoch 16, Train Loss: 755.1654, Val Loss: 774.3531\n",
      "Epoch 17, Train Loss: 789.8601, Val Loss: 827.2210\n",
      "Epoch 18, Train Loss: 755.3821, Val Loss: 743.2994\n",
      "Epoch 19, Train Loss: 757.8143, Val Loss: 800.2900\n",
      "Epoch 20, Train Loss: 738.6730, Val Loss: 816.2247\n"
     ]
    }
   ],
   "source": [
    "# 模块7：运行一次训练并可视化结果\n",
    "\n",
    "model, train_losses, val_losses = train_model(epochs=20)\n",
    "plot_losses(train_losses, val_losses, title=\"CVAE Training with 20 epochs\")\n",
    "\n",
    "# 从验证集拿一个batch演示生成\n",
    "train_loader, val_loader = get_dataloaders()\n",
    "images, attrs = next(iter(val_loader))\n",
    "sample_attrs = attrs[:16]\n",
    "generated_images = generate_images(model, sample_attrs, device=device, num_images=16)\n",
    "show_images(generated_images, title=\"Sample Generated Images\", save_path=\"generated_sample.png\")\n",
    "\n",
    "\n",
    "# 修改某个属性（如Smiling）\n",
    "modified_attrs = sample_attrs.clone()\n",
    "modified_attrs[:, 31] = 1  # 假设第32列为Smiling属性\n",
    "modified_generated = generate_images(model, modified_attrs, device=device, num_images=16)\n",
    "show_images(modified_generated, title=\"Modified 'Smiling' Attribute Images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模块8：多次训练求平均收敛点\n",
    "下面的代码是回答您的第一点需求：相同轮次下，多次训练取得平均收敛曲线。比如您想在固定的 epochs=20 下，运行5次训练，然后计算这5次训练在各个epoch的平均损失和验证损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/5\n",
      "Epoch 1, Train Loss: 343044610082.1857, Val Loss: 1313.6351\n",
      "Epoch 2, Train Loss: 1222.3490, Val Loss: 1145.7170\n",
      "Epoch 3, Train Loss: 1043.6424, Val Loss: 984.0562\n",
      "Epoch 4, Train Loss: 942.9426, Val Loss: 912.9837\n",
      "Epoch 5, Train Loss: 885.9244, Val Loss: 931.4077\n",
      "Epoch 6, Train Loss: 854.1712, Val Loss: 857.8686\n",
      "Epoch 7, Train Loss: 831.7365, Val Loss: 894.2481\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_train_losses, avg_val_losses\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 示例：运行5次，并画出平均收敛曲线\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m avg_train_losses, avg_val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mmultiple_runs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m plot_losses(avg_train_losses, avg_val_losses, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Curve over 5 runs (20 epochs)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36mmultiple_runs\u001b[0;34m(epochs, runs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(runs):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mruns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     _, train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     all_train_losses\u001b[38;5;241m.\u001b[39mappend(train_losses)\n\u001b[1;32m     10\u001b[0m     all_val_losses\u001b[38;5;241m.\u001b[39mappend(val_losses)\n",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(epochs, latent_dim, cond_dim, learning_rate)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     14\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_one_epoch(model, train_loader, optimizer, device)\n\u001b[0;32m---> 15\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     17\u001b[0m     val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorc_test1/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorc_test1/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1448\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1448\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorc_test1/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1412\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1414\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorc_test1/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1243\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorc_test1/lib/python3.12/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorc_test1/lib/python3.12/multiprocessing/connection.py:256\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorc_test1/lib/python3.12/multiprocessing/connection.py:423\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 423\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorc_test1/lib/python3.12/multiprocessing/connection.py:1118\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1118\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m   1120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorc_test1/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 模块8：多次实验以求平均收敛点\n",
    "def multiple_runs(epochs=20, runs=5):\n",
    "    all_train_losses = []\n",
    "    all_val_losses = []\n",
    "\n",
    "    for run in range(runs):\n",
    "        print(f\"Run {run+1}/{runs}\")\n",
    "        _, train_losses, val_losses = train_model(epochs=epochs)\n",
    "        all_train_losses.append(train_losses)\n",
    "        all_val_losses.append(val_losses)\n",
    "\n",
    "    # 将多次训练的损失求平均\n",
    "    avg_train_losses = np.mean(all_train_losses, axis=0)\n",
    "    avg_val_losses = np.mean(all_val_losses, axis=0)\n",
    "    return avg_train_losses, avg_val_losses\n",
    "\n",
    "# 示例：运行5次，并画出平均收敛曲线\n",
    "avg_train_losses, avg_val_losses = multiple_runs(epochs=20, runs=5)\n",
    "plot_losses(avg_train_losses, avg_val_losses, title=\"Average Curve over 5 runs (20 epochs)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模块9：改变训练轮次进行多组实验\n",
    "接下来是第二点需求：在完成多次相同轮次训练后，我们还希望改变轮数，比如尝试 epochs = 10, 20, 30, 40，每个轮数都进行多次训练，以比较平均收敛点和验证性能。这可以在一个循环中进行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模块9：改变轮次并多次训练对比\n",
    "epoch_list = [10, 20, 30, 40]\n",
    "runs_per_setting = 3  # 每个轮次数多次训练的次数\n",
    "\n",
    "results = {}\n",
    "for ep in epoch_list:\n",
    "    print(f\"==== Testing {ep} epochs ====\")\n",
    "    avg_train_losses, avg_val_losses = multiple_runs(epochs=ep, runs=runs_per_setting)\n",
    "    results[ep] = (avg_train_losses, avg_val_losses)\n",
    "\n",
    "# 对比不同epoch设置的最终验证损失或曲线\n",
    "plt.figure(figsize=(8,6))\n",
    "for ep in epoch_list:\n",
    "    avg_train, avg_val = results[ep]\n",
    "    plt.plot(avg_val, label=f'{ep} epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss Comparison for Different Epoch Counts')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorc_test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
